spring:
  application:
    name: qa-agent-server
  
  # HTTP Client timeout configuration
  http:
    client:
      connect-timeout: 60s
      read-timeout: 300s

  ai:
    google:
      genai:
        api-key: ${GEMINI_API_KEY}
        project-id: ${GEMINI_PROJECT_ID}
        chat:
          options:
            model: ${GEMINI_MODEL:gemini-2.5-flash}
            temperature: ${GEMINI_TEMPERATURE:0.3}
    
    # Ollama 설정
    ollama:
      chat:
        options:
          model: llama3.2 # Default model, can be overridden by user
        base-url: http://localhost:11434 # Default Ollama host (assuming local installation)
      models: # Custom models list for the application to display/use
        - llama3.2
        - qwen2.5:3b

    # MCP Client 설정 (Playwright MCP Server 연결)
    mcp:
      client:
        sync-timeout: 150s
        stdio:
          connections:
            playwright:
              command: npx
              args:
                - "--yes"
                - "@playwright/mcp@latest"
                - "--timeout-action"
                - "300000"
                - "--timeout-navigation"
                - "300000"
              env:
                NPM_CONFIG_REGISTRY: "https://registry.npmjs.org/"

            filesystem:
              command: npx
              args:
                - "--yes"
                - "@modelcontextprotocol/server-filesystem"
                - "./qa-prompts"
              env:
                NPM_CONFIG_REGISTRY: "https://registry.npmjs.org/"
  thymeleaf:
    cache: false

server:
  port: 8090

app:
  gemini:
    models:
      - gemini-2.5-flash
      - gemini-2.5-pro
      -
logging:
  level:
    com.auto.qa: DEBUG
    org.springframework.ai: INFO
